{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk0lB3p28JZASFkDwH7fQO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c6qyGc_TfeHE"
      },
      "outputs": [],
      "source": [
        "# Notebook: Hugging Face Pre-Built Task Pipelines\n",
        "# Author: Thomas Purk\n",
        "# Date: 2025-04-01\n",
        "# Reference: https://huggingface.co/docs/transformers/v4.50.0/en/main_classes/pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face Pre-Built Task Pipelines\n",
        "\n",
        "The Pipeline class of the Hugging Face Transformers package can instantiate new pipeline objects using a 'task' string. At this time there are 29 pre-defined pipeline strings covering text, audio, video, and image type tasks.\n",
        "\n",
        "This notebook investigates common pre-defined task-based pipelines and their default parameters and metadata.\n",
        "\n",
        "- Sentiment Analysis\n",
        "- Text Generation\n",
        "- Mask Filling\n",
        "- Named Entity Recognition\n",
        "- Question Answering\n",
        "- Summarization\n",
        "- Translation"
      ],
      "metadata": {
        "id": "T2ZsRvwXgzWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Package Installs\n",
        "\n",
        "#!pip install transformers\n",
        "\n",
        "!pip list | grep transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx3X6nXFjXee",
        "outputId": "d3da9b5b-dd09-4935-d07e-45375e60a1e2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence-transformers              3.4.1\n",
            "transformers                       4.50.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Notebook\n",
        "\n",
        "# General\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "logging.getLogger(\"transformers\").setLevel(logging.WARNING) # Suppress unnecessary logging\n",
        "\n",
        "# Visualization\n",
        "import pprint\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Data, Science, & Math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP\n",
        "import transformers\n",
        "from transformers.pipelines import SUPPORTED_TASKS\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "W7EvteAUiELV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_np_types(obj):\n",
        "    '''Recursively convert NumPy types to standard Python types.\n",
        "    This function originated from ChatGPT.\n",
        "\n",
        "    Parameters:\n",
        "        obj (object): The object to convert.\n",
        "\n",
        "    Returns:\n",
        "        object: The converted object.\n",
        "\n",
        "    '''\n",
        "    if isinstance(obj, (np.float32, np.float64)):\n",
        "        return float(obj)  # Convert NumPy float to Python float\n",
        "    elif isinstance(obj, (np.int32, np.int64)):\n",
        "        return int(obj)  # Convert NumPy int to Python int\n",
        "    elif isinstance(obj, dict):\n",
        "        return {key: convert_np_types(value) for key, value in obj.items()}  # Recurse into dict\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_np_types(item) for item in obj]  # Recurse into list\n",
        "    return obj  # Return unchanged if it's not a NumPy type\n",
        "\n",
        "\n",
        "\n",
        "def get_task_metadata(task_name, framework):\n",
        "    '''Assemble metadata about each predefined pipeline tasks. This is a\n",
        "    work-around to the get_default_model_and_revision() function which\n",
        "    returns an error for 'translation task'.\n",
        "\n",
        "    Parameters:\n",
        "        task_name (str): An items from transformers.pipeline.SUPPORTED_TASKS.\n",
        "        framework (str): \"pt\" for Pytorch or \"tf\" for TensorFlow\n",
        "\n",
        "    '''\n",
        "\n",
        "    meta_dict = {}\n",
        "    task = SUPPORTED_TASKS[task_name]\n",
        "    meta_dict['task_name'] = task_name\n",
        "\n",
        "    # Handle special cases where the default dict is parameratized by language\n",
        "    if('model'in task['default']):\n",
        "        model_name, model_revision = task['default']['model'][framework]\n",
        "        meta_dict['model_name'] = model_name\n",
        "        meta_dict['model_revision'] = model_revision\n",
        "    elif(('en','fr') in task['default']):\n",
        "        meta_dict['model_name'] = 'N/A'\n",
        "        model_name, model_revision = task['default'][('en','fr')]['model'][framework]\n",
        "        meta_dict['model_name'] = model_name\n",
        "        meta_dict['model_revision'] = model_revision\n",
        "\n",
        "    if(framework in task):\n",
        "        meta_dict['model_class'] = str(task[framework][0])\n",
        "    else:\n",
        "        meta_dict['model_class'] = 'N/A'\n",
        "\n",
        "    if('type' in task):\n",
        "        meta_dict['model_type'] = task['type']\n",
        "    else:\n",
        "        meta_dict['model_type'] = 'N/A'\n",
        "\n",
        "    if('impl' in task):\n",
        "        meta_dict['model_impl'] = task['impl']\n",
        "    else:\n",
        "        meta_dict['model_impl'] = 'N/A'\n",
        "\n",
        "    return meta_dict\n",
        "\n",
        "# Report on each pre-built task\n",
        "# Print meta data about each built in task\n",
        "for task_name in SUPPORTED_TASKS.keys():\n",
        "    m = get_task_metadata(task_name, 'pt')\n",
        "    print(f'Task Name: {m[\"task_name\"]}')\n",
        "    print('-----------------------------')\n",
        "    print(f'Model Type: {m[\"model_type\"]}')\n",
        "    print(f'Model Name: {m[\"model_name\"]}')\n",
        "    print(f'Model Revision: {m[\"model_revision\"]}')\n",
        "    print(f'Model Class: {m[\"model_class\"]}')\n",
        "    print(f'Model Implementation: {m[\"model_impl\"]}')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmI7I5NNjNkr",
        "outputId": "c4bfff9d-06a9-4566-df44-0122983a1576"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task Name: audio-classification\n",
            "-----------------------------\n",
            "Model Type: audio\n",
            "Model Name: superb/wav2vec2-base-superb-ks\n",
            "Model Revision: 372e048\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.audio_classification.AudioClassificationPipeline'>\n",
            "\n",
            "Task Name: automatic-speech-recognition\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: facebook/wav2vec2-base-960h\n",
            "Model Revision: 22aad52\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForCTC'>\n",
            "Model Implementation: <class 'transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline'>\n",
            "\n",
            "Task Name: text-to-audio\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: suno/bark-small\n",
            "Model Revision: 1dbd7a1\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForTextToWaveform'>\n",
            "Model Implementation: <class 'transformers.pipelines.text_to_audio.TextToAudioPipeline'>\n",
            "\n",
            "Task Name: feature-extraction\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: distilbert/distilbert-base-cased\n",
            "Model Revision: 6ea8117\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModel'>\n",
            "Model Implementation: <class 'transformers.pipelines.feature_extraction.FeatureExtractionPipeline'>\n",
            "\n",
            "Task Name: text-classification\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
            "Model Revision: 714eb0f\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.text_classification.TextClassificationPipeline'>\n",
            "\n",
            "Task Name: token-classification\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: dbmdz/bert-large-cased-finetuned-conll03-english\n",
            "Model Revision: 4c53496\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.token_classification.TokenClassificationPipeline'>\n",
            "\n",
            "Task Name: question-answering\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: distilbert/distilbert-base-cased-distilled-squad\n",
            "Model Revision: 564e9b5\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForQuestionAnswering'>\n",
            "Model Implementation: <class 'transformers.pipelines.question_answering.QuestionAnsweringPipeline'>\n",
            "\n",
            "Task Name: table-question-answering\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: google/tapas-base-finetuned-wtq\n",
            "Model Revision: e3dde19\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForTableQuestionAnswering'>\n",
            "Model Implementation: <class 'transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline'>\n",
            "\n",
            "Task Name: visual-question-answering\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: dandelin/vilt-b32-finetuned-vqa\n",
            "Model Revision: d0a1f6a\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForVisualQuestionAnswering'>\n",
            "Model Implementation: <class 'transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline'>\n",
            "\n",
            "Task Name: document-question-answering\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: impira/layoutlm-document-qa\n",
            "Model Revision: beed3c4\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForDocumentQuestionAnswering'>\n",
            "Model Implementation: <class 'transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline'>\n",
            "\n",
            "Task Name: fill-mask\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: distilbert/distilroberta-base\n",
            "Model Revision: fb53ab8\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForMaskedLM'>\n",
            "Model Implementation: <class 'transformers.pipelines.fill_mask.FillMaskPipeline'>\n",
            "\n",
            "Task Name: summarization\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: sshleifer/distilbart-cnn-12-6\n",
            "Model Revision: a4f8f3e\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>\n",
            "Model Implementation: <class 'transformers.pipelines.text2text_generation.SummarizationPipeline'>\n",
            "\n",
            "Task Name: translation\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: google-t5/t5-base\n",
            "Model Revision: a9723ea\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>\n",
            "Model Implementation: <class 'transformers.pipelines.text2text_generation.TranslationPipeline'>\n",
            "\n",
            "Task Name: text2text-generation\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: google-t5/t5-base\n",
            "Model Revision: a9723ea\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>\n",
            "Model Implementation: <class 'transformers.pipelines.text2text_generation.Text2TextGenerationPipeline'>\n",
            "\n",
            "Task Name: text-generation\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: openai-community/gpt2\n",
            "Model Revision: 607a30d\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>\n",
            "Model Implementation: <class 'transformers.pipelines.text_generation.TextGenerationPipeline'>\n",
            "\n",
            "Task Name: zero-shot-classification\n",
            "-----------------------------\n",
            "Model Type: text\n",
            "Model Name: facebook/bart-large-mnli\n",
            "Model Revision: d7645e1\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline'>\n",
            "\n",
            "Task Name: zero-shot-image-classification\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: openai/clip-vit-base-patch32\n",
            "Model Revision: 3d74acf\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForZeroShotImageClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.zero_shot_image_classification.ZeroShotImageClassificationPipeline'>\n",
            "\n",
            "Task Name: zero-shot-audio-classification\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: laion/clap-htsat-fused\n",
            "Model Revision: cca9e28\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModel'>\n",
            "Model Implementation: <class 'transformers.pipelines.zero_shot_audio_classification.ZeroShotAudioClassificationPipeline'>\n",
            "\n",
            "Task Name: image-classification\n",
            "-----------------------------\n",
            "Model Type: image\n",
            "Model Name: google/vit-base-patch16-224\n",
            "Model Revision: 3f49326\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForImageClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.image_classification.ImageClassificationPipeline'>\n",
            "\n",
            "Task Name: image-feature-extraction\n",
            "-----------------------------\n",
            "Model Type: image\n",
            "Model Name: google/vit-base-patch16-224\n",
            "Model Revision: 3f49326\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModel'>\n",
            "Model Implementation: <class 'transformers.pipelines.image_feature_extraction.ImageFeatureExtractionPipeline'>\n",
            "\n",
            "Task Name: image-segmentation\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: facebook/detr-resnet-50-panoptic\n",
            "Model Revision: d53b52a\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForImageSegmentation'>\n",
            "Model Implementation: <class 'transformers.pipelines.image_segmentation.ImageSegmentationPipeline'>\n",
            "\n",
            "Task Name: image-to-text\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: ydshieh/vit-gpt2-coco-en\n",
            "Model Revision: 5bebf1e\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForVision2Seq'>\n",
            "Model Implementation: <class 'transformers.pipelines.image_to_text.ImageToTextPipeline'>\n",
            "\n",
            "Task Name: image-text-to-text\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: llava-hf/llava-onevision-qwen2-0.5b-ov-hf\n",
            "Model Revision: 2c9ba3b\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForImageTextToText'>\n",
            "Model Implementation: <class 'transformers.pipelines.image_text_to_text.ImageTextToTextPipeline'>\n",
            "\n",
            "Task Name: object-detection\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: facebook/detr-resnet-50\n",
            "Model Revision: 1d5f47b\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForObjectDetection'>\n",
            "Model Implementation: <class 'transformers.pipelines.object_detection.ObjectDetectionPipeline'>\n",
            "\n",
            "Task Name: zero-shot-object-detection\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: google/owlvit-base-patch32\n",
            "Model Revision: cbc355f\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForZeroShotObjectDetection'>\n",
            "Model Implementation: <class 'transformers.pipelines.zero_shot_object_detection.ZeroShotObjectDetectionPipeline'>\n",
            "\n",
            "Task Name: depth-estimation\n",
            "-----------------------------\n",
            "Model Type: image\n",
            "Model Name: Intel/dpt-large\n",
            "Model Revision: bc15f29\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForDepthEstimation'>\n",
            "Model Implementation: <class 'transformers.pipelines.depth_estimation.DepthEstimationPipeline'>\n",
            "\n",
            "Task Name: video-classification\n",
            "-----------------------------\n",
            "Model Type: video\n",
            "Model Name: MCG-NJU/videomae-base-finetuned-kinetics\n",
            "Model Revision: 488eb9a\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForVideoClassification'>\n",
            "Model Implementation: <class 'transformers.pipelines.video_classification.VideoClassificationPipeline'>\n",
            "\n",
            "Task Name: mask-generation\n",
            "-----------------------------\n",
            "Model Type: multimodal\n",
            "Model Name: facebook/sam-vit-huge\n",
            "Model Revision: 87aecf0\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForMaskGeneration'>\n",
            "Model Implementation: <class 'transformers.pipelines.mask_generation.MaskGenerationPipeline'>\n",
            "\n",
            "Task Name: image-to-image\n",
            "-----------------------------\n",
            "Model Type: image\n",
            "Model Name: caidas/swin2SR-classical-sr-x2-64\n",
            "Model Revision: cee1c92\n",
            "Model Class: <class 'transformers.models.auto.modeling_auto.AutoModelForImageToImage'>\n",
            "Model Implementation: <class 'transformers.pipelines.image_to_image.ImageToImagePipeline'>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Sentiment Analysis Pipeline\n",
        "# Classifies text\n",
        "\n",
        "# Create a Default 'text-classification'/\n",
        "sa_pipeline = pipeline('sentiment-analysis')\n",
        "\n",
        "# 'sentiment-analysis' is an alias for 'text-classification'\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('text-classification', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = sa_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = [\n",
        "    \"I absolutely love this new phone! It's fast and the camera is amazing.\",\n",
        "    \"The service at the restaurant was terrible, and the food was cold when it arrived.\",\n",
        "    \"I'm feeling pretty neutral about the movie—it had some good moments but was mostly forgettable.\",\n",
        "    \"Winning the competition was the best experience of my life!\",\n",
        "    \"I can't believe how frustrating this software update is; nothing works properly now.\"\n",
        "]\n",
        "\n",
        "# Execute the sentiment analysis model\n",
        "results = sa_pipeline(inputs=inputs)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df['inputs'] = inputs\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "e4SCbofRzyDF",
        "outputId": "0a43b70d-cb28-4dd0-ea6b-0dccbecbae79"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'text-classification',\n",
              " 'model_name': 'distilbert/distilbert-base-uncased-finetuned-sst-2-english',\n",
              " 'model_revision': '714eb0f',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.text_classification.TextClassificationPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'NEGATIVE', 1: 'POSITIVE'}\n",
            "\n",
            "Model Card: https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label     score                                             inputs\n",
              "0  POSITIVE  0.999887  I absolutely love this new phone! It's fast an...\n",
              "1  NEGATIVE  0.999531  The service at the restaurant was terrible, an...\n",
              "2  NEGATIVE  0.999625  I'm feeling pretty neutral about the movie—it ...\n",
              "3  POSITIVE  0.999847  Winning the competition was the best experienc...\n",
              "4  NEGATIVE  0.999699  I can't believe how frustrating this software ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cd27d27-ae55-48dd-b9fa-2d61f9800c1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "      <th>inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999887</td>\n",
              "      <td>I absolutely love this new phone! It's fast an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999531</td>\n",
              "      <td>The service at the restaurant was terrible, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999625</td>\n",
              "      <td>I'm feeling pretty neutral about the movie—it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.999847</td>\n",
              "      <td>Winning the competition was the best experienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999699</td>\n",
              "      <td>I can't believe how frustrating this software ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cd27d27-ae55-48dd-b9fa-2d61f9800c1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cd27d27-ae55-48dd-b9fa-2d61f9800c1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cd27d27-ae55-48dd-b9fa-2d61f9800c1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c233ff8e-a62c-4ccd-b0f1-ae1e26010e17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c233ff8e-a62c-4ccd-b0f1-ae1e26010e17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c233ff8e-a62c-4ccd-b0f1-ae1e26010e17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b73319fb-bc13-47f7-b6df-692270e6782a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b73319fb-bc13-47f7-b6df-692270e6782a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NEGATIVE\",\n          \"POSITIVE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00014936907331361494,\n        \"min\": 0.9995306730270386,\n        \"max\": 0.9998869895935059,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9995306730270386,\n          0.9996994733810425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inputs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The service at the restaurant was terrible, and the food was cold when it arrived.\",\n          \"I can't believe how frustrating this software update is; nothing works properly now.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Text Generation Pipeline\n",
        "# Classifies text\n",
        "\n",
        "# Create a Default 'text-classification'/\n",
        "tg_pipeline = pipeline(\n",
        "    task='text-generation'\n",
        ")\n",
        "\n",
        "# 'sentiment-analysis' is an alias for 'text-classification'\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('text-generation', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = tg_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = [\n",
        "    \"I absolutely love this new phone! It's fast and the camera is amazing.\",\n",
        "    \"The service at the restaurant was terrible, and the food was cold when it arrived.\",\n",
        "    \"I'm feeling pretty neutral about the movie—it had some good moments but was mostly forgettable.\",\n",
        "    \"Winning the competition was the best experience of my life!\",\n",
        "    \"I can't believe how frustrating this software update is; nothing works properly now.\"\n",
        "]\n",
        "\n",
        "# Execute the text generation model\n",
        "results = tg_pipeline(text_inputs=inputs)\n",
        "\n",
        "# Formate the resuls\n",
        "results = [x[0]['generated_text'] for x in results]\n",
        "\n",
        "# Create a table of inputs and results\n",
        "df = pd.DataFrame(results, columns=['results'])\n",
        "df['inputs'] = inputs\n",
        "\n",
        "for i, r in df.iterrows():\n",
        "    print(f'\\nInput:')\n",
        "    display(r[\"inputs\"])\n",
        "    print(f'\\nGenerated Text: ')\n",
        "    display(r[\"results\"])\n",
        "    print('\\n---------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x1yoq7atxSuU",
        "outputId": "a4df7e7e-44c7-4314-dc4e-a245032a2495"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'text-generation',\n",
              " 'model_name': 'openai-community/gpt2',\n",
              " 'model_revision': '607a30d',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.text_generation.TextGenerationPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'LABEL_0', 1: 'LABEL_1'}\n",
            "\n",
            "Model Card: https://huggingface.co/openai-community/gpt2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I absolutely love this new phone! It's fast and the camera is amazing.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I absolutely love this new phone! It's fast and the camera is amazing. I would say it's my 5th one I've owned.\\n\\n\\nI purchased mine from the local store yesterday, and I'm really impressed with how good it is\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The service at the restaurant was terrible, and the food was cold when it arrived.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The service at the restaurant was terrible, and the food was cold when it arrived.\\n\\nAccording to the complaint, it appeared that the staff had placed order online and a lady was able to get it to her. Asking people around the dining'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I'm feeling pretty neutral about the movie—it had some good moments but was mostly forgettable.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I'm feeling pretty neutral about the movie—it had some good moments but was mostly forgettable. However, I'm more interested in that second half of the movie: what if the government decides to follow a couple of old, bad actors instead of\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Winning the competition was the best experience of my life!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"Winning the competition was the best experience of my life! Being a part of your own company, you've got to know what is happening right there, or it can be hard to know when you're going to have all the fun you've been\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I can't believe how frustrating this software update is; nothing works properly now.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I can't believe how frustrating this software update is; nothing works properly now. I'll update soon but won't. And I'm still having issues.\\n\\nIt was already a while ago that I went to the hardware site asking if I could\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Text Generation Pipeline, But Specify the Model\n",
        "# Classifies text\n",
        "\n",
        "# Create a Default 'text-generation'\n",
        "tg_pipeline = pipeline(\n",
        "    task='text-generation',\n",
        "    model='distilgpt2'\n",
        ")\n",
        "\n",
        "# 'sentiment-analysis' is an alias for 'text-classification'\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('text-generation', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = tg_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = [\n",
        "    \"I absolutely love this new phone! It's fast and the camera is amazing.\",\n",
        "    \"The service at the restaurant was terrible, and the food was cold when it arrived.\",\n",
        "    \"I'm feeling pretty neutral about the movie—it had some good moments but was mostly forgettable.\",\n",
        "    \"Winning the competition was the best experience of my life!\",\n",
        "    \"I can't believe how frustrating this software update is; nothing works properly now.\"\n",
        "]\n",
        "\n",
        "# Execute the text generation model\n",
        "results = tg_pipeline(text_inputs=inputs)\n",
        "\n",
        "# Formate the resuls\n",
        "results = [x[0]['generated_text'] for x in results]\n",
        "\n",
        "# Create a table of inputs and results\n",
        "df = pd.DataFrame(results, columns=['results'])\n",
        "df['inputs'] = inputs\n",
        "\n",
        "for i, r in df.iterrows():\n",
        "    print(f'\\nInput:')\n",
        "    display(r[\"inputs\"])\n",
        "    print(f'\\nGenerated Text: ')\n",
        "    display(r[\"results\"])\n",
        "    print('\\n---------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GS6bkWFj9SgD",
        "outputId": "2f3f8404-b6e5-4ece-e583-397ec2689648"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'text-generation',\n",
              " 'model_name': 'openai-community/gpt2',\n",
              " 'model_revision': '607a30d',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.text_generation.TextGenerationPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'LABEL_0'}\n",
            "\n",
            "Model Card: https://huggingface.co/distilgpt2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I absolutely love this new phone! It's fast and the camera is amazing.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I absolutely love this new phone! It's fast and the camera is amazing. There has been a lot of thought and has been a lot of discussion regarding the design with the new phone, and it's so cool. It fits on Android 6.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The service at the restaurant was terrible, and the food was cold when it arrived.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The service at the restaurant was terrible, and the food was cold when it arrived. I had to go out to pick the pizza a day later to order pizza. After the service was over service, the only problem was my dog ate pizza.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I'm feeling pretty neutral about the movie—it had some good moments but was mostly forgettable.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'I\\'m feeling pretty neutral about the movie—it had some good moments but was mostly forgettable.\\n\\n\\n\\nAfter seeing Batman v Superman II: Dawn of Justice (2000) you thought the movie had a \"fun\" ending, and you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Winning the competition was the best experience of my life!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Winning the competition was the best experience of my life! But for the last 12 months, I’ve noticed that’s a long way to go! So, I have now decided to try and become a photographer myself!\\nYou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n",
            "\n",
            "Input:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I can't believe how frustrating this software update is; nothing works properly now.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"I can't believe how frustrating this software update is; nothing works properly now. Thanks to this great feature I had to go through a while and actually have to go through the manual to learn the steps. This update allows you to view the current version\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Fill Mask Pipeline\n",
        "# Classifies text\n",
        "\n",
        "# Create a Default 'text-classification'\n",
        "fm_pipeline = pipeline(\n",
        "    task='fill-mask',\n",
        ")\n",
        "\n",
        "# 'sentiment-analysis' is an alias for 'text-classification'\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('fill-mask', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = fm_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = [\n",
        "    \"I absolutely love this <mask>! It's fast and the camera is <mask>.\",\n",
        "    \"The service at the restaurant was <mask>, and the food was <mask> when it arrived.\",\n",
        "    \"I'm feeling pretty <mask> about the movie—it had some good moments but was mostly <mask>.\",\n",
        "    \"Winning the <mask> was the best experience of my life!\",\n",
        "    \"I can't believe how frustrating this <mask> update is; nothing works properly now.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Execute the mask fill model\n",
        "results = fm_pipeline(\n",
        "    inputs=inputs,\n",
        "    top_k=2\n",
        ")\n",
        "\n",
        "# Format # Print the results\n",
        "print(json.dumps(convert_np_types(results), indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KmzlZefa-qa2",
        "outputId": "bb6d21aa-92e7-458e-b8d4-a86328bb66ab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'fill-mask',\n",
              " 'model_name': 'distilbert/distilroberta-base',\n",
              " 'model_revision': 'fb53ab8',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForMaskedLM'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.fill_mask.FillMaskPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'LABEL_0', 1: 'LABEL_1'}\n",
            "\n",
            "Model Card: https://huggingface.co/distilbert/distilroberta-base\n",
            "\n",
            "[\n",
            "    [\n",
            "        [\n",
            "            {\n",
            "                \"score\": 0.3331633508205414,\n",
            "                \"token\": 2280,\n",
            "                \"token_str\": \" camera\",\n",
            "                \"sequence\": \"<s>I absolutely love this camera! It's fast and the camera is<mask>.</s>\"\n",
            "            },\n",
            "            {\n",
            "                \"score\": 0.03793039172887802,\n",
            "                \"token\": 1028,\n",
            "                \"token_str\": \" phone\",\n",
            "                \"sequence\": \"<s>I absolutely love this phone! It's fast and the camera is<mask>.</s>\"\n",
            "            }\n",
            "        ],\n",
            "        [\n",
            "            {\n",
            "                \"score\": 0.12083110958337784,\n",
            "                \"token\": 12058,\n",
            "                \"token_str\": \" gorgeous\",\n",
            "                \"sequence\": \"<s>I absolutely love this<mask>! It's fast and the camera is gorgeous.</s>\"\n",
            "            },\n",
            "            {\n",
            "                \"score\": 0.11521915346384048,\n",
            "                \"token\": 4406,\n",
            "                \"token_str\": \" sharp\",\n",
            "                \"sequence\": \"<s>I absolutely love this<mask>! It's fast and the camera is sharp.</s>\"\n",
            "            }\n",
            "        ]\n",
            "    ],\n",
            "    [\n",
            "        [\n",
            "            {\n",
            "                \"score\": 0.12758521735668182,\n",
            "                \"token\": 4206,\n",
            "                \"token_str\": \" excellent\",\n",
            "                \"sequence\": \"<s>The service at the restaurant was excellent, and the food was<mask> when it arrived.</s>\"\n",
            "            },\n",
            "            {\n",
            "                \"score\": 0.04832185432314873,\n",
            "                \"token\": 9297,\n",
            "                \"token_str\": \" exceptional\",\n",
            "                \"sequence\": \"<s>The service at the restaurant was exceptional, and the food was<mask> when it arrived.</s>\"\n",
            "            }\n",
            "        ],\n",
            "        [\n",
            "            {\n",
            "                \"score\": 0.09350449591875076,\n",
            "                \"token\": 9214,\n",
            "                \"token_str\": \" frozen\",\n",
            "                \"sequence\": \"<s>The service at the restaurant was<mask>, and the food was frozen when it arrived.</s>\"\n",
            "            },\n",
            "            {\n",
            "                \"score\": 0.0598214752972126,\n",
            "                \"token\": 1665,\n",
            "                \"token_str\": \" served\",\n",
            "                \"sequence\": \"<s>The service at the restaurant was<mask>, and the food was served when it arrived.</s>\"\n",
            "            }\n",
            "        ]\n",
            "    ],\n",
            "    [\n",
            "        [\n",
            "            {\n",
            "                \"score\": 0.29031991958618164,\n",
            "                \"token\": 205,\n",
            "                \"token_str\": \" good\",\n",
            "                \"sequence\": \"<s>I'm feeling pretty good about the movie\\u2014it had some good moments but was mostly<mask>.</s>\"\n",
            "            },\n",
            "            {\n",
            "                \"score\": 0.15128596127033234,\n",
            "                \"token\": 7168,\n",
            "                \"token_str\": \" optimistic\",\n",
            "                \"sequence\": \"<s>I'm feeling pretty optimistic about the movie\\u2014it had some good moments but was mostly<mask>.</s>\"\n",
            "            }\n",
            "        ],\n",
            "        [\n",
            "            {\n",
            "                \"score\": 0.12989558279514313,\n",
            "                \"token\": 15305,\n",
            "                \"token_str\": \" boring\",\n",
            "                \"sequence\": \"<s>I'm feeling pretty<mask> about the movie\\u2014it had some good moments but was mostly boring.</s>\"\n",
            "            },\n",
            "            {\n",
            "                \"score\": 0.10331448167562485,\n",
            "                \"token\": 6770,\n",
            "                \"token_str\": \" disappointing\",\n",
            "                \"sequence\": \"<s>I'm feeling pretty<mask> about the movie\\u2014it had some good moments but was mostly disappointing.</s>\"\n",
            "            }\n",
            "        ]\n",
            "    ],\n",
            "    [\n",
            "        {\n",
            "            \"score\": 0.34734177589416504,\n",
            "            \"token\": 11395,\n",
            "            \"token_str\": \" lottery\",\n",
            "            \"sequence\": \"Winning the lottery was the best experience of my life!\"\n",
            "        },\n",
            "        {\n",
            "            \"score\": 0.03575924411416054,\n",
            "            \"token\": 1270,\n",
            "            \"token_str\": \" title\",\n",
            "            \"sequence\": \"Winning the title was the best experience of my life!\"\n",
            "        }\n",
            "    ],\n",
            "    [\n",
            "        {\n",
            "            \"score\": 0.146084263920784,\n",
            "            \"token\": 34569,\n",
            "            \"token_str\": \" firmware\",\n",
            "            \"sequence\": \"I can't believe how frustrating this firmware update is; nothing works properly now.\"\n",
            "        },\n",
            "        {\n",
            "            \"score\": 0.0861474797129631,\n",
            "            \"token\": 665,\n",
            "            \"token_str\": \" latest\",\n",
            "            \"sequence\": \"I can't believe how frustrating this latest update is; nothing works properly now.\"\n",
            "        }\n",
            "    ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Named Entity Recognition\n",
        "# Classifies tokens\n",
        "# NOTE: 'ner' is an alias for 'token-classification'\n",
        "\n",
        "# Create a Default 'ner' pipeline\n",
        "ner_pipeline = pipeline(\n",
        "    task='ner',\n",
        ")\n",
        "\n",
        "# 'sentiment-analysis' is an alias for 'text-classification'\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('token-classification', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = ner_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = [\n",
        "    \"The Titanic sank in the Atlantic Ocean in 1912.\",\n",
        "    \"Pablo Picasso was a Spanish painter and sculptor known for co-founding Cubism.\",\n",
        "    \"J.K. Rowling wrote the Harry Potter series, starting with 'Harry Potter and the Sorcerer’s Stone'.\",\n",
        "    \"The Great Wall of China is one of the Seven Wonders of the World.\",\n",
        "    \"The Oscars, also known as the Academy Awards, recognize excellence in the film industry.\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "# Execute the token classification model\n",
        "results = ner_pipeline(\n",
        "    inputs=inputs,\n",
        "    grouped_entities=True # Re-assembles \"Pablo\" & \"Pacaso\" tokens\n",
        ")\n",
        "\n",
        "# Format # Print the results\n",
        "print(json.dumps(convert_np_types(results), indent=4))"
      ],
      "metadata": {
        "id": "VQmuIRS0F8c-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6868d0e-18e0-40ce-a17d-9b9dc7cea22d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'token-classification',\n",
              " 'model_name': 'dbmdz/bert-large-cased-finetuned-conll03-english',\n",
              " 'model_revision': '4c53496',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.token_classification.TokenClassificationPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC'}\n",
            "\n",
            "Model Card: https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english\n",
            "\n",
            "[\n",
            "    [\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.8621680736541748,\n",
            "            \"word\": \"Titanic\",\n",
            "            \"start\": 4,\n",
            "            \"end\": 11\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"LOC\",\n",
            "            \"score\": 0.9976879358291626,\n",
            "            \"word\": \"Atlantic Ocean\",\n",
            "            \"start\": 24,\n",
            "            \"end\": 38\n",
            "        }\n",
            "    ],\n",
            "    [\n",
            "        {\n",
            "            \"entity_group\": \"PER\",\n",
            "            \"score\": 0.9983973503112793,\n",
            "            \"word\": \"Pablo Picasso\",\n",
            "            \"start\": 0,\n",
            "            \"end\": 13\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.9976692795753479,\n",
            "            \"word\": \"Spanish\",\n",
            "            \"start\": 20,\n",
            "            \"end\": 27\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.9095709323883057,\n",
            "            \"word\": \"Cubi\",\n",
            "            \"start\": 71,\n",
            "            \"end\": 75\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"ORG\",\n",
            "            \"score\": 0.5459023118019104,\n",
            "            \"word\": \"##sm\",\n",
            "            \"start\": 75,\n",
            "            \"end\": 77\n",
            "        }\n",
            "    ],\n",
            "    [\n",
            "        {\n",
            "            \"entity_group\": \"PER\",\n",
            "            \"score\": 0.9973369240760803,\n",
            "            \"word\": \"J\",\n",
            "            \"start\": 0,\n",
            "            \"end\": 1\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"PER\",\n",
            "            \"score\": 0.9897366166114807,\n",
            "            \"word\": \"K. Rowling\",\n",
            "            \"start\": 2,\n",
            "            \"end\": 12\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.9827728867530823,\n",
            "            \"word\": \"Harry Potter\",\n",
            "            \"start\": 23,\n",
            "            \"end\": 35\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.9852359294891357,\n",
            "            \"word\": \"Harry Potter and the Sorcerer \\u2019 s Stone\",\n",
            "            \"start\": 59,\n",
            "            \"end\": 96\n",
            "        }\n",
            "    ],\n",
            "    [\n",
            "        {\n",
            "            \"entity_group\": \"LOC\",\n",
            "            \"score\": 0.889606237411499,\n",
            "            \"word\": \"Great Wall of China\",\n",
            "            \"start\": 4,\n",
            "            \"end\": 23\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.9909523129463196,\n",
            "            \"word\": \"Seven Wonders of the World\",\n",
            "            \"start\": 38,\n",
            "            \"end\": 64\n",
            "        }\n",
            "    ],\n",
            "    [\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.990799069404602,\n",
            "            \"word\": \"Oscars\",\n",
            "            \"start\": 4,\n",
            "            \"end\": 10\n",
            "        },\n",
            "        {\n",
            "            \"entity_group\": \"MISC\",\n",
            "            \"score\": 0.9948880672454834,\n",
            "            \"word\": \"Academy Awards\",\n",
            "            \"start\": 30,\n",
            "            \"end\": 44\n",
            "        }\n",
            "    ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Summarization Pipeline\n",
        "# Classifies text\n",
        "\n",
        "# Create a Default 'summarization'\n",
        "sum_pipeline = pipeline(\n",
        "    task='summarization',\n",
        ")\n",
        "\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('summarization', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = sum_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = '''Traditional hand tool woodworking is a craft that emphasizes\n",
        "precision, skill, and patience. Unlike modern power tools, hand tools such as\n",
        "chisels, hand planes, and saws allow artisans to shape wood with a high level\n",
        "of control. This method of woodworking has been practiced for centuries, relying\n",
        " on techniques passed down through generations to create furniture, cabinetry,\n",
        " and intricate wood carvings.\n",
        "\n",
        "One of the key benefits of working with hand tools is the ability to produce\n",
        "fine, detailed joinery without the noise and dust associated with power tools.\n",
        "Techniques like dovetail joints, mortise and tenon connections, and hand-planed\n",
        "surfaces showcase the craftsmanship involved. Woodworkers often select tools\n",
        "based on the type of wood they are working with, ensuring smooth cuts and\n",
        "precise fittings.\n",
        "\n",
        "In addition to its practical advantages, hand tool woodworking fosters a deep\n",
        "connection between the artisan and the material. The rhythmic motion of a hand\n",
        "saw or the delicate shaving of a plane allows for a meditative experience that\n",
        "many woodworkers find rewarding. As more people seek sustainable and traditional\n",
        " crafting methods, hand tool woodworking continues to thrive, preserving\n",
        " historical skills while promoting an appreciation for high-quality, handmade\n",
        " pieces.\n",
        "'''\n",
        "\n",
        "\n",
        "# Execute the text generation model\n",
        "results = sum_pipeline(inputs)\n",
        "results = results[0]['summary_text']\n",
        "\n",
        "# Format # Print the\n",
        "print('Result:')\n",
        "display(HTML(f\"<pre style='white-space: pre-wrap; word-wrap: break-word;'>{results}</pre>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "9mu8O4_Fv5iE",
        "outputId": "45b19a99-5cd0-4c3b-c337-186e4833393c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'summarization',\n",
              " 'model_name': 'sshleifer/distilbart-cnn-12-6',\n",
              " 'model_revision': 'a4f8f3e',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.text2text_generation.SummarizationPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'}\n",
            "\n",
            "Model Card: https://huggingface.co/sshleifer/distilbart-cnn-12-6\n",
            "\n",
            "Result:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style='white-space: pre-wrap; word-wrap: break-word;'> Traditional hand tool woodworking is a craft that emphasizes precision, skill and patience . Hand tools have been used for centuries to make furniture and woodwork . Hand tool tools are used to create intricate woodcarvings and intricate carvings . Woodworkers often select tools based on the type of wood they are working with, ensuring smooth cuts .</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation: The summary is ALMOST there, but only makes sense under great effort\n",
        "# but the reader."
      ],
      "metadata": {
        "id": "jVidXTgM2h-P"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Question Answering\n",
        "# Classifies tokens\n",
        "\n",
        "\n",
        "# Create a Default 'question-answering' pipeline\n",
        "qa_pipeline = pipeline(\n",
        "    task='question-answering'\n",
        ")\n",
        "\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('question-answering', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = qa_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "# Use the three paragraphs about handtool woodworking defined above.\n",
        "context = inputs\n",
        "\n",
        "question = \"What are some tools used in hand tool woodworking?\"\n",
        "\n",
        "# Execute the text generation model\n",
        "results = qa_pipeline(\n",
        "    question=question,\n",
        "    context=context\n",
        ")\n",
        "\n",
        "# Format # Print the results\n",
        "print(json.dumps(convert_np_types(results), indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZezsVSwT-B0u",
        "outputId": "8bc747a3-8231-4f77-a2c7-7e76ba0fe675"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'question-answering',\n",
              " 'model_name': 'distilbert/distilbert-base-cased-distilled-squad',\n",
              " 'model_revision': '564e9b5',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForQuestionAnswering'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.question_answering.QuestionAnsweringPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'LABEL_0', 1: 'LABEL_1'}\n",
            "\n",
            "Model Card: https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad\n",
            "\n",
            "{\n",
            "    \"score\": 0.9732940793037415,\n",
            "    \"start\": 139,\n",
            "    \"end\": 169,\n",
            "    \"answer\": \"chisels, hand planes, and saws\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Default Translation, with specific model\n",
        "# Classifies tokens\n",
        "\n",
        "\n",
        "# Create a Default 'translation' pipeline\n",
        "tr_pipeline = pipeline(\n",
        "    task='translation',\n",
        "    model=\"Helsinki-NLP/opus-mt-fr-en\"\n",
        ")\n",
        "\n",
        "print('\\nMetadata:')\n",
        "display(get_task_metadata('translation', 'pt'))\n",
        "print()\n",
        "\n",
        "\n",
        "# Get model configuration\n",
        "model_config = tr_pipeline.model.config\n",
        "print(f'Class Labels: {model_config.id2label}')\n",
        "print()\n",
        "print(f'Model Card: https://huggingface.co/{model_config._name_or_path}')\n",
        "print()\n",
        "\n",
        "inputs = [\n",
        "    \"Bonjour, comment allez-vous ?\",\n",
        "    \"Il fait beau aujourd'hui.\",\n",
        "    \"Je voudrais un café, s'il vous plaît.\",\n",
        "    \"Où est la gare ?\",\n",
        "    \"Merci, au revoir.\"\n",
        "]\n",
        "\n",
        "'''English Reference\n",
        "\n",
        "    \"Hello, how are you?\",\n",
        "    \"The weather is nice today.\",\n",
        "    \"I would like a coffee, please.\",\n",
        "    \"Where is the train station?\",\n",
        "    \"Thank you, goodbye.\"\n",
        "'''\n",
        "\n",
        "\n",
        "# Execute the text generation model\n",
        "results = tr_pipeline(inputs)\n",
        "\n",
        "# Format # Print the results\n",
        "print(json.dumps(convert_np_types(results), indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "SY0wp62bzMNJ",
        "outputId": "ed06fe69-c36e-463f-dd52-94e15c010976"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'task_name': 'translation',\n",
              " 'model_name': 'google-t5/t5-base',\n",
              " 'model_revision': 'a9723ea',\n",
              " 'model_class': \"<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>\",\n",
              " 'model_type': 'text',\n",
              " 'model_impl': transformers.pipelines.text2text_generation.TranslationPipeline}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Labels: {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'}\n",
            "\n",
            "Model Card: https://huggingface.co/Helsinki-NLP/opus-mt-fr-en\n",
            "\n",
            "[\n",
            "    {\n",
            "        \"translation_text\": \"Hello, how are you?\"\n",
            "    },\n",
            "    {\n",
            "        \"translation_text\": \"It's beautiful today.\"\n",
            "    },\n",
            "    {\n",
            "        \"translation_text\": \"I'd like some coffee, please.\"\n",
            "    },\n",
            "    {\n",
            "        \"translation_text\": \"Where's the station?\"\n",
            "    },\n",
            "    {\n",
            "        \"translation_text\": \"Thank you, bye.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}