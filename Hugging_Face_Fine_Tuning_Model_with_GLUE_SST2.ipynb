{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSdKP3SrR7/yWId8rTgSsf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Notebook: Hugging Face Fine-Tuning Model with GLUE SST2\n",
        "# Author: Thomas Purk\n",
        "# Date: 2025-04-02\n",
        "# Reference: https://huggingface.co/docs/tokenizers/index\n",
        "# Reference: https://huggingface.co/docs/datasets/en/index\n",
        "# Reference: https://huggingface.co/datasets/nyu-mll/glue\n",
        "# Reference: https://huggingface.co/google-bert/bert-base-cased\n",
        "# Reference: https://huggingface.co/docs/evaluate/index"
      ],
      "metadata": {
        "id": "f7Gw0r9GRIOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face Fine-Tuning Model with GLUE SST2\n",
        "\n",
        "This notebook demonstrates fine-tuning of the 'bert-base-cased' model checkpoint using the GLUE SST2 dataset. The original model was trained for the a mask filling task. These steps replace the mask filling head with a sentiment anlysis head. This is accomplished using the Hugging Face Trainer module and the GLUE SST2 dataset which has \"positive\" and \"negative\" labels.\n",
        "\n",
        "**Model**\n",
        "\n",
        "> Pretrained model on English language using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model is case-sensitive: it makes a difference between english and English.\n",
        "\n",
        "https://huggingface.co/google-bert/bert-base-cased\n",
        "\n",
        "\n",
        "**Dataset**\n",
        "\n",
        ">The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. It uses the two-way (positive/negative) class split, with only sentence-level labels.\n",
        "\n",
        "\n",
        ">Wang, Alex, Amanpreet, Singh, Julian, Michael, Felix, Hill, Omer, Levy, Samuel R., Bowman. \"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.\" In the Proceedings of ICLR. 2019.\n",
        "\n",
        "\n",
        "https://huggingface.co/datasets/nyu-mll/glue"
      ],
      "metadata": {
        "id": "bg7086WP6-Yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Setup"
      ],
      "metadata": {
        "id": "-5ssC3NLmZxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Package Installs\n",
        "\n",
        "#!pip install transformers evaluate datasets\n",
        "!pip list | grep \"transformers*\\|datasets*\\|evaluate*\""
      ],
      "metadata": {
        "id": "B-g_dJU5RNn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Notebook\n",
        "\n",
        "# General\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "logging.getLogger(\"transformers\").setLevel(logging.WARNING) # Suppress unnecessary logging\n",
        "\n",
        "# Visualization\n",
        "import pprint\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Data, Science, & Math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP\n",
        "import transformers\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoConfig\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import pipeline\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "import torch\n",
        "\n",
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "u9k5dEkJAdfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_id = torch.cuda.current_device()\n",
        "    gpu_name = torch.cuda.get_device_name(device_id)\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Running on CPU.\")"
      ],
      "metadata": {
        "id": "Ul8zo2U4jto-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook functions\n",
        "\n",
        "def tokenize_function(data):\n",
        "    \"\"\" Tokenizes the senteces in a dataset item\n",
        "\n",
        "        Args:\n",
        "            data (dictionary): An item from the dataset\n",
        "\n",
        "        Returns:\n",
        "            dict: The sentence encoded as numbers\n",
        "    \"\"\"\n",
        "\n",
        "    # Get and return the grouped embeddings from the input dictonary\n",
        "    return tokenizer(\n",
        "        data[\"sentence\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "def compute_metrics(evals_preds):\n",
        "    \"\"\" Computes the metrics to describe the performance of the model results\n",
        "\n",
        "        Args:\n",
        "            evals_preds (EvalPrediction): a named tuple including a predictions and label_ids field\n",
        "\n",
        "        Returns:\n",
        "            dict: The value describing the performance\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Unpack the dictionary into variables\n",
        "    # logits: an array of predictions as logits\n",
        "    # labels: an array of sequence classification task results 0: is seqence 1: is not sequence\n",
        "    logits, labels = evals_preds\n",
        "\n",
        "    # Load the metrics associated with the MRPC dataset with the evaluate.load() function\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "    # Convert the logits to their predicted class\n",
        "    # It contains the logits for each element of the dataset we passed to predict()\n",
        "    # To transform them into predictions that we can compare to our labels,\n",
        "    # we need to take the index with the maximum value on the second axis\n",
        "    predictions = np.argmax(\n",
        "        a=logits,\n",
        "        axis=-1\n",
        "    )\n",
        "\n",
        "    # Call the compute function\n",
        "    return metric.compute(\n",
        "        predictions=predictions,\n",
        "        references=labels\n",
        "    )"
      ],
      "metadata": {
        "id": "4hzSfzK_Lp8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasetup"
      ],
      "metadata": {
        "id": "Vs1wwaTZmeX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SST2 data set from GLUE https://huggingface.co/datasets/nyu-mll/glue\n",
        "ds_sst2 = load_dataset(\"glue\", \"sst2\")\n",
        "#ds_sst2 = load_dataset(\"yelp_review_full\")\n",
        "type(ds_sst2)"
      ],
      "metadata": {
        "id": "2XdBs7Qn4euA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Dataset Info\n",
        "display(ds_sst2.column_names)\n",
        "print('')\n",
        "print(f'Total Training Rows: {ds_sst2.num_rows[\"train\"]}')\n",
        "print(f'Total Test Rows: {ds_sst2.num_rows[\"test\"]}')"
      ],
      "metadata": {
        "id": "BU8wMto9Q_9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Records\n",
        "print(f'Example Train Record: {ds_sst2[\"train\"][0]}')\n",
        "print(f'Example Test Record: {ds_sst2[\"test\"][0]}')"
      ],
      "metadata": {
        "id": "qSfPcxtEu8Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate Labels\n",
        "\n",
        "# Debug Possible Errors\n",
        "# Error on GPU: \"RuntimeError: CUDA error: device-side assert triggered\"\n",
        "# Error on CPU: \"IndexError: Target -1 is out of bounds.\"\n",
        "# Check for any -1 labels\n",
        "\n",
        "print(f'Unique Training Labels: {set(ds_sst2[\"train\"][\"label\"])}')\n",
        "print('')\n",
        "print(f'Unique Test Labels: {set(ds_sst2[\"test\"][\"label\"])}')"
      ],
      "metadata": {
        "id": "_HFn-mWkWGrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The sst2 test dataset's labels are hidden (-1), so they cannot be user for validation during trianing.\n",
        "# The Train dataset is much larger than we are going to use in this demonstration.\n",
        "# So it can be split into train and test\n",
        "\n",
        "# Split the original train set into 80% train, 20% test\n",
        "split_dataset = ds_sst2[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Access the splits\n",
        "ds_train_split = split_dataset[\"train\"].shuffle(seed=42).select(range(4000))\n",
        "ds_test_split = split_dataset[\"test\"].shuffle(seed=42).select(range(800))\n",
        "\n",
        "\n",
        "print(f'Training Rows: {ds_train_split.num_rows}')\n",
        "print(f'Test Rows: {ds_test_split.num_rows}')\n",
        "print('')"
      ],
      "metadata": {
        "id": "U8ZxPn3QYH7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the Tokenizer & Model based on the checkpoint name\n",
        "\n",
        "# Define the Model Checkpoint to Fine-Tune\n",
        "#checkpoint = \"distilbert/distilbert-base-uncased\"\n",
        "checkpoint = \"google-bert/bert-base-cased\"\n",
        "\n",
        "# Automatically select a matching tokenizer based on the checkpoint name\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# How many labels does the dataset and model have?\n",
        "ds_class_labels = ds_train_split.features[\"label\"]\n",
        "config = AutoConfig.from_pretrained(checkpoint)\n",
        "\n",
        "print(f'The dataset has labels: {ds_class_labels.names}')\n",
        "print('')\n",
        "print(f'The model checkpoint has labels: {config.id2label}')"
      ],
      "metadata": {
        "id": "ZTLFXMSf4dO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom labels for the new model \"head\"\n",
        "custom_id2label = {}\n",
        "custom_label2id = {}\n",
        "\n",
        "# Loop each label in the dataset class names\n",
        "# The model will be trained (fine-tuned) to predict these names\n",
        "for l in ds_class_labels.names:\n",
        "    id = ds_class_labels.str2int(l) # the id of the dataset label\n",
        "    custom_id2label[id] = l\n",
        "    custom_label2id[l] = id\n",
        "\n",
        "print(f'custom_id2label: {custom_id2label}')\n",
        "print(f'custom_label2id: {custom_label2id}')"
      ],
      "metadata": {
        "id": "Farg5UAs1EDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically select a matching sequence classification model based on the checkpoint name\n",
        "# NOTE: \"AutoModelForSequenceClassification\" is the same class used by the \"text-classification\" default pipeline\n",
        "\n",
        "# Create the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(custom_id2label)\n",
        ")\n",
        "\n",
        "# Update label mappings\n",
        "model.config.id2label = custom_id2label\n",
        "model.config.label2id = custom_label2id"
      ],
      "metadata": {
        "id": "LJWWV7rVr9z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "# Create a new dictionary of tokenized datasets\n",
        "\n",
        "ds_train_tokenize = ds_train_split.map(tokenize_function, batched=True)\n",
        "ds_test_tokenize = ds_test_split.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "w5Ccts1V-m2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the Fine-Tuning\n",
        "\n",
        "# Create a new data collator to assemble sample data for training\n",
        "# DataCollatorWithPadding - dynamically pada the inputs received.\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Define a set of hyperparameters for the Trainer to use\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test-trainer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"none\" # disables the weights and biases (wandb) callback in the TrainingArguments\n",
        ")\n",
        "\n",
        "\n",
        "# Create a new trainier by passing in the objects created above\n",
        "# This trainer will fine-tune the model for sentiment analysis using the GLUE SST2 dataset\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train_tokenize,\n",
        "    eval_dataset=ds_test_tokenize,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "OctQQBy4TjBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the training process\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "uKCLmvG8ubBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the model on some sample data\n",
        "# Some code from ChatGPT\n",
        "\n",
        "# NOTE: Colab's free GPU has been activated\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load model and move it to the device\n",
        "model = model.to(device)\n",
        "\n",
        "sentences = [\n",
        "    \"I absolutely love this new phone! It's fast and the camera is amazing.\",\n",
        "    \"The service at the restaurant was terrible, and the food was cold when it arrived.\",\n",
        "    \"I'm feeling pretty neutral about the movieâ€”it had some good moments but was mostly forgettable.\",\n",
        "    \"Winning the competition was the best experience of my life!\",\n",
        "    \"I can't believe how frustrating this software update is; nothing works properly now.\"\n",
        "]\n",
        "\n",
        "# Create a pipeline for sentiment classification\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Test the model on new data\n",
        "results = classifier(sentences)\n",
        "\n",
        "# Print results\n",
        "for sentence, result in zip(sentences, results):\n",
        "    print(f\"Sentence: {sentence}\\nPredicted Sentiment: {result}\\n\")\n"
      ],
      "metadata": {
        "id": "zwIJbxvDeCzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZqFm_r6vQj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}